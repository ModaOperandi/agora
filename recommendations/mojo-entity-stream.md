

# High level entity streaming from mojo

Replicating data owned by some other service (currently mostly only mojo) can be a burden when the data is too low-level. For example the marketing-email service's bootstrap takes ~6-8hours after each field added
Subscribing to binlogger and building your own data out of it means that we have to re-write the business logic from above the raw data in every new service.

### Goals
1. Easy near-real time data extraction from mojo (where binlogger has proven too complicated)
2. Easy bootstrapping of new data

### Proposal
A Mojo queue that writes fully detailed high level entities into a stream.
Whenever an active record object changes, queue them for streaming.
Services can listen to these streams and update their copy of the data if needed
Have an option to write into the stream all existing objects

#### Advantages:
Quicker bootstrap (currently reindexing all active products takes ~20 minutes in production)
No need to extract the business logic from mojo into the new services when we want to deal with data unrelated to what the service owns
The schema is generated by spec -> easily sharable between services

#### Disadvantages:
Another queue in mojo

A sample spec of variants, with data needed for Algolia indexing:
https://github.com/ModaOperandi/event-models/pull/1/files

